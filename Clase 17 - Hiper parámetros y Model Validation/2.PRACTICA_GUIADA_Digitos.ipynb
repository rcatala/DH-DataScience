{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0tsg1OiniD6y"
   },
   "source": [
    "## PRACTICA GUIADA: Explorando dígitos escritos a mano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zirh1UJciD61"
   },
   "source": [
    "Consideremos una parte del problema de reconocimiento óptico de caracteres (OCR, optical character recognition): la identificación de dígitos escritos a mano. \n",
    "\n",
    "En aplicaciones reales, este problema incluye tanto localizar como identificar caracteres en una imagen. Aquí tomaremos un atajo, y usaremos un dataset de dígitos preformateados que se incluyen en Scikit-Learn, evitandonos el trabajo extra que no es relevante en este momento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKEkN7rQiD63"
   },
   "source": [
    "### Cargamos y visualizamos los datos de dígitos\n",
    "\n",
    "Usamos la interfaz de acceso a datos de Scikit-Learn y los observamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "naU_WvVmiD65"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TXbe9Ei1iD7B"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PeuM_kj0iD7H"
   },
   "source": [
    "Los datos de imágenes se almacenan como un array de tres dimensiones: 1797 muestras, cada una compuesta por una grilla de 8 x 8 píxeles (cada uno con tonos de grises).\n",
    "\n",
    "Vamos a visualizar los primeros cien dígitos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nWpQHOxSiD7J"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(digits.images[i], cmap='binary')\n",
    "    ax.text(0.05, 0.05, str(digits.target[i]),\n",
    "            transform=ax.transAxes, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DP-6ztKviD7N"
   },
   "source": [
    "Para poder trabajar con estos datos en Scikit-learn, necesitamos una representación bidimensional de tamaño ``[n_samples, n_features]``. \n",
    "Podemos lograr esta transformación tratando cada píxel en la imagen como una feature distinta: es decir, estirando cada imagen-matriz para obtener un array unidimensional de longitud 64 píxeles que representa cada dígito. \n",
    "\n",
    "Adicionalmente, necesitamos el vector target, que nos da la etiqueta previamente determinada para cada dígito. \n",
    "Estas dos cantidades están incluidas en el dataset de prueba, bajo los atributos ``data`` y ``target``, respectivamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fbwOYfw1iD7O"
   },
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8UOdWRuiD7T"
   },
   "outputs": [],
   "source": [
    "y = digits.target\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whwUPBjqiD7a"
   },
   "source": [
    "Aquí vemos que hay 1,797 muestras y 64 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yPmNTpm_iD7e"
   },
   "source": [
    "### Aprendizaje no supervisado: Reducción de la dimensionalidad \n",
    "\n",
    "Nos gustaría visualizar nuestros puntos en el espacio de parámetros de 64 dimensiones, pero es muy difícil visualizar efectivamente puntos en un espacio de tan alta dimensionalidad. \n",
    "En cambio, vamos a reducir la dimensión a 2, usando un método no supervisado. \n",
    "Aquí, haremos uso del algoritmo llamado *Isomap* (del conjunto de algoritmos conocidos como Manifold Learning) y tranformaremos los datos a dos dimensiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nET__SuUiD7f"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "iso = Isomap(n_components=2)\n",
    "iso.fit(digits.data)\n",
    "data_projected = iso.transform(digits.data)\n",
    "data_projected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qLpQOrgwiD7k"
   },
   "source": [
    "Vemos que los datos proyectados ahora son bidimensionales.\n",
    "\n",
    "Vamos a plotear estos datos para ver si podemos aprender algo de su estructura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AsCh1BF2iD7l"
   },
   "outputs": [],
   "source": [
    "plt.scatter(data_projected[:, 0], data_projected[:, 1], c=digits.target,\n",
    "            edgecolor='none', alpha=0.5,\n",
    "            cmap=plt.cm.get_cmap('nipy_spectral', 10))\n",
    "plt.colorbar(label='digit label', ticks=range(10))\n",
    "plt.clim(-0.5, 9.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fDGpv19fiD7r"
   },
   "source": [
    "Este plot nos dá cierta intuición sobre cuán bien se separan varios números en el espacio de parámetros de 64 dimensiones. \n",
    "\n",
    "Por ejemplo, los ceros (en negro) y los unos (en púrpura) tienen muy poco overlap en el espacio de parámetros. \n",
    "\n",
    "Intuitivamente, esto tiene sentido: un cero está vacío en el centro de la imagen, mientras un uno generalmente tendrá píxeles oscuros en el centro. \n",
    "\n",
    "Por otro lado, parece haber un espectro más o menos contínuo entre los 1 y los 4: podemos entender esto observando que algunas personas dibuja 1s con \"sombreritos\", lo cuál causa que se parezcan a 4s.  \n",
    "\n",
    "En general, sin embargo, los diferentes grupos parecen estar relativamente bien separados,  esto nos dice que incluso un algoritmo muy sencillo de clasificación podría performar correctamente sobre estos datos. Vamos a intentarlo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bn8movOSiD7t"
   },
   "source": [
    "### Clasificación de dígitos\n",
    "\n",
    "Vamos a aplicar un algoritmo de clasificación al dataset de dígitos. \n",
    "\n",
    "Como hicimos previamente con Iris, vamos a separar los datos en sets de training y testing, y ajustar un modelo de tipo Naive Bayes Gausiano:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcIInv5RiD7v"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AL8FsyHAiD7z"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(Xtrain, ytrain)\n",
    "y_model = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cLDXFpdwi4oS"
   },
   "source": [
    "¿Por qué aquí hicimos solamente una separación en train y test? ¿Optimizamos algún hiper parámetro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edpuU2sLiD72"
   },
   "source": [
    "Ahora que hemos realizado la predicción, podemos validar su accuracy comparando los valores verdaderos del test set con las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0U_lwf-1iD73"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yoc7ZiLoiD78"
   },
   "source": [
    "Incluso con este modelo extremadamente simple, logramos más de 80% de accuracy para la clasificación de dígitos! \n",
    "\n",
    "Sin embargo, esta única métrica no nos dice *dónde* hemos cometido errores. Una forma de visualizar esto es usar la *matriz de confusión*, que podemos computar con Scikit-Learn y plotear con Seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2T-fR87CiD79"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(ytest, y_model)\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C9CmhggliD8A"
   },
   "source": [
    "Esto nos muestra dónde tienden a estar los puntos mal etiquetados. Por ejemplo, un gran número de 2 son mal clasificados bien como 1s o como 8s. \n",
    "\n",
    "Otra forma de ganar intuición sobre las características del modelo es plotear los dígitos de entrada nuevamente, pero esta vez con las etiquetas predichas. \n",
    "\n",
    "Usaremos el color verde para las etiquetas correctas y rojo paras incorrectas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fY1toZRliD8B"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "test_images = Xtest.reshape(-1, 8, 8)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(test_images[i], cmap='binary')\n",
    "    ax.text(0.05, 0.05, str(y_model[i]),\n",
    "            transform=ax.transAxes,\n",
    "            color='green' if (ytest[i] == y_model[i]) else 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oq_w3BUHiD8G"
   },
   "source": [
    "Examinando este subset de los datos, podemos ganar cierto insight con respecto a dónde el algoritmo podría no estar performando óptimamente. \n",
    "Para ir más allá de nuestro %80 de ratio de clasificación  correcta, podríamos movernos a un algoritmo más sofisticado, como Support Vector Machines, Random Forests u otras técnicas  de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vFTJebdRjdjN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2.PRACTICA_GUIADA_Digitos.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
