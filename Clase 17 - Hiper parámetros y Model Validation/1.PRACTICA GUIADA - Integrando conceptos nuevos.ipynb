{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FxnwL4Tmcknx"
   },
   "source": [
    "# PRACTICA GUIADA: Analizando conceptos nuevos \n",
    "\n",
    "\n",
    "Estudiaremos un ejemplo de usar cross-validation para computar las validation curves de una clase de modelos.\n",
    "\n",
    "Aquí usaremos un modelo de *regresión polinómica*:  Notemos que esto sigue siendo regresión lineal (en los parámetros)\n",
    "\n",
    "Por ejemplo, un polinomio de grado 1 ajusta una línea recta a los datos; para los parámetros del modelo $a$ y $b$:\n",
    "\n",
    "$$\n",
    "y = ax + b\n",
    "$$\n",
    "\n",
    "Un polinomio de grado 3 ajusta una curva cúbica a los datos; para parámetros $a, b, c, d$: \n",
    "\n",
    "$$\n",
    "y = ax^3 + bx^2 + cx + d\n",
    "$$\n",
    "\n",
    "Podemos generalizar esto a cualquier número de features polinómicas.\n",
    "\n",
    "En Scikit-Learn, podemos implementar esto con una simple regresión lineal combinada con el preprocesador polinómico (polynomial preprocessor).\n",
    "\n",
    "Usaremos un *pipeline* para organizar secuencialmente estas operaciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A9usVQQlcknz"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                         LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8VKn5UmKckn5"
   },
   "source": [
    "Ahora vamos a crear algunos datos sintéticos (artificiales, inventados), \n",
    "sobre los que luego ajustaremos nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZsdC5fNckn7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_data(N, err=1.0, rseed=1):\n",
    "    # randomly sample the data\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    X = rng.rand(N, 1) ** 2\n",
    "    y = 10 - 1. / (X.ravel() + 0.1)\n",
    "    if err > 0:\n",
    "        y += err * rng.randn(N)\n",
    "    return X, y\n",
    "\n",
    "X, y = make_data(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y2x59bXickn_"
   },
   "source": [
    "Ahora podemos visualizar nuestros datos, junto con los ajustes de modelos polinómicos de varios grados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bz80ZK_7ckoB"
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # plot formatting\n",
    "\n",
    "X_test = np.linspace(-0.1, 1.1, 500).reshape(-1,1)\n",
    "\n",
    "plt.scatter(X.ravel(), y, color='black')\n",
    "axis = plt.axis()\n",
    "for degree in [1, 3, 5]:\n",
    "    y_test = PolynomialRegression(degree).fit(X, y).predict(X_test)\n",
    "    plt.plot(X_test.ravel(), y_test, label='degree={0}'.format(degree))\n",
    "plt.xlim(-0.1, 1.0)\n",
    "plt.ylim(-2, 12)\n",
    "plt.legend(loc='best')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A6JfJxgNckoF"
   },
   "source": [
    "En este caso, \"la perilla\" que controla la complejidad del modelo es el grado del polinomio, el cuál puede ser cualquier entero no negativo.\n",
    "\n",
    "Una pregunta interesante para hacernos:  ¿Qué grado de polinomio provee un compromiso apropiado entre sesgo (under-fitting) y varianza (over-fitting)?\n",
    "\n",
    "Podemos avanzar visualizando la validation curve para este dataset y modelo particular; esto se puede hacer fácilmente usando la función ``validation_curve`` provista por Scikit-Learn.\n",
    "\n",
    "Dado un modelo, un dataset, un nombre de parámetro, y un rango para explorar, esta función computará automáticamente tanto el score de entrenamiento como el de validación a lo largo del rango: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-KG8-rxkckoH"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "degree = np.arange(0, 21)\n",
    "train_score, val_score = validation_curve(PolynomialRegression(), X, y, 'polynomialfeatures__degree'\n",
    "                                          , degree, cv=7)\n",
    "\n",
    "plt.plot(degree, np.mean(train_score, axis=1), color='blue', label='training score')\n",
    "plt.plot(degree, np.mean(val_score, axis=1), color='red', label='validation score')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('score')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mxu88BvRckoL"
   },
   "source": [
    "Este gráfico muestra precisamente el comportamiento cualitativo que esperamos: el score de entrenamiento siempre es mayor que el score de validación; el score de entrenamiento crece de manera monótona junto con la complejidad del modelo; y el score de validación alcanza un máximo antes de finalmente caer a medida que el modelo sobre-ajusta. \n",
    "\n",
    "De la validation curve, podemos interpretar que el compromiso óptimo entre sesgo y varianza se encuentra con un polinomio de tercer orden; podemos computar y mostrar este ajuste sobre los datos originales: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fxrQaPpCgeMl"
   },
   "source": [
    "Noten que el modelo elegido en base a los datos de train/validación es entrenado ahora sobre el 100% de los datos de train/validación y es testeado con observaciones nunca utilizadas para entrenar ni validar. \n",
    "En este caso no hubo split entre train/validación y test porque generamos X de test por separado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T0DVsFBvckoM"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X.ravel(), y)\n",
    "lim = plt.axis()\n",
    "y_test = PolynomialRegression(3).fit(X, y).predict(X_test)\n",
    "plt.plot(X_test.ravel(), y_test);\n",
    "plt.axis(lim)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hhu7H0V9ckoQ"
   },
   "source": [
    "Notar que hallar este modelo óptimo no requirió que computemos sólo el score de entrenamiento, sino que examinando la relación entre los scores de entrenamiento y validación pudimos obtener un insight válido sobre la performance del modelo."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "1.PRACTICA GUIADA - Integrando conceptos nuevos.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
